#include "flockmtl/model_manager/model.hpp"
#include "nlohmann/json.hpp"
#include <gtest/gtest.h>
#include <memory>
#include <string>

namespace flockmtl {
using json = nlohmann::json;

class ModelManagerTest : public ::testing::Test {
protected:
    void SetUp() override {
        auto con = Config::GetConnection();
        con.Query(" CREATE SECRET ("
                  "       TYPE OPENAI,"
                  "    API_KEY 'your-api-key');");
        con.Query("      CREATE SECRET ("
                  "            TYPE AZURE_LLM,"
                  "         API_KEY 'your-api-key',"
                  "   RESOURCE_NAME 'your-resource-name',"
                  "     API_VERSION '2023-05-15');");
        con.Query("  CREATE SECRET ("
                  "       TYPE OLLAMA,"
                  "    API_URL '127.0.0.1:11434');");
    }

    void TearDown() override {
    }
};

// Test Model initialization with valid model configuration
TEST_F(ModelManagerTest, ModelInitialization) {
    // Create a model configuration with required parameters
    json model_config = {
            {"model_name", "gpt-4o-test"},
            {"model", "gpt-4o"},
            {"provider", "openai"},
            {"context_window", "128000"},
            {"max_output_tokens", "8000"},
            {"temperature", "0.7"}};

    EXPECT_NO_THROW({
        Model model(model_config);
        ModelDetails details = model.GetModelDetails();
        EXPECT_EQ(details.model_name, "gpt-4o-test");
        EXPECT_EQ(details.model, "gpt-4o");
        EXPECT_EQ(details.provider_name, "openai");
        EXPECT_EQ(details.context_window, 128000);
        EXPECT_EQ(details.max_output_tokens, 8000);
        EXPECT_FLOAT_EQ(details.temperature, 0.7f);
    });
}

// Test Model initialization with minimal required parameters
TEST_F(ModelManagerTest, ModelInitializationMinimal) {
    // Create a model config with only model_name (other details should be fetched from DB)
    json model_config = {
            {"model_name", "gpt-4o-test"}};
    // Model initialization should fetch remaining details from database
    EXPECT_NO_THROW({
        Model model(model_config);
        ModelDetails details = model.GetModelDetails();
        EXPECT_EQ(details.model_name, "gpt-4o-test");
        EXPECT_EQ(details.model, "gpt-4o");
        EXPECT_EQ(details.provider_name, "openai");
        EXPECT_EQ(details.context_window, 128000);
        EXPECT_EQ(details.max_output_tokens, 8000);
    });
}

// Test Model initialization with invalid configuration
TEST_F(ModelManagerTest, ModelInitializationInvalid) {
    // Create a model config without required model_name
    json invalid_model_config = {
            {"model", "gpt-4o-test"},
            {"provider", "openai"}};
    // Model initialization should fail due to missing model_name
    EXPECT_THROW(Model model(invalid_model_config), std::invalid_argument);
    // Model name that doesn't exist in the system
    json nonexistent_model = {
            {"model_name", "non_existent_model_123"}};
    // Model initialization should fail for non-existent model
    EXPECT_THROW(Model model(nonexistent_model), std::runtime_error);
}

// Test model provider selection based on provider name
TEST_F(ModelManagerTest, ProviderSelection) {
    // Test OpenAI provider
    json openai_config = {
            {"model_name", "gpt-4o-test"}};
    EXPECT_NO_THROW({
        Model openai_model(openai_config);
        EXPECT_EQ(openai_model.GetModelDetails().provider_name, "openai");
    });
    // Test Azure provider
    json azure_config = {
            {"model_name", "azure-gpt-4o-mini"}};
    EXPECT_NO_THROW({
        Model azure_model(azure_config);
        EXPECT_EQ(azure_model.GetModelDetails().provider_name, "azure");
    });
    // Test Ollama provider
    json ollama_config = {
            {"model_name", "llama3"}};
    EXPECT_NO_THROW({
        Model ollama_model(ollama_config);
        EXPECT_EQ(ollama_model.GetModelDetails().provider_name, "ollama");
    });
}

// Test model details retrieval
TEST_F(ModelManagerTest, GetModelDetails) {
    json model_config = {
            {"model_name", "gpt-4o-test"},
            {"model", "gpt-4o"},
            {"provider", "openai"},
            {"context_window", "128000"},
            {"max_output_tokens", "8000"},
            {"temperature", "0.7"},
            {"tuple_format", "XML"},
            {"batch_size", "10"}};

    Model model(model_config);
    ModelDetails details = model.GetModelDetails();

    EXPECT_EQ(details.model_name, "gpt-4o-test");
    EXPECT_EQ(details.model, "gpt-4o");
    EXPECT_EQ(details.provider_name, "openai");
    EXPECT_EQ(details.context_window, 128000);
    EXPECT_EQ(details.max_output_tokens, 8000);
    EXPECT_FLOAT_EQ(details.temperature, 0.7f);
    EXPECT_EQ(details.tuple_format, "XML");
    EXPECT_EQ(details.batch_size, 10);
}

}// namespace flockmtl